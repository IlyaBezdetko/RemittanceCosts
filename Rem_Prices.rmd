---
title: "Short Analytical Story on Remittance Costs"
author: "Ilia Bezdetko"
output: html_document
---

High-level overview of the analysis performed:

**Exploratory Analysis:**

  * Data Quality Testing (i.e. count of missing values, check data types of values in the table attributes, outliers, etc.)
  * Generated histograms for variables of interest, as well as sub-setted variabels conditional on different factors
  * Calculated distribution summary statistics
  * Analyzed trends and produced trendlines with 95% confidence intervals
  * Analyzed relationships between different drivers using simple linear regression and correlation tests.
  
**Construction of the dataset for predictive modeling:**

  * Aggregated data as a timeseries using different aggregation functions (e.g. average, max, min, count, etc.)
  * Interpolated between data points to construct monthly timeseries from the raw data.  Interpolation had to be used since the aggregated timeseries were not given at fixed time-intervals.  The interpolation was done in FinCAD, work papers are available upon request.

**Modeling:**

  * Explored a different regression-based modeling frameworks (linear regression, lasso, ridge, weighted least squares, splines etc.)
  * Split the dataset into in-sample and out-of-sample datasets
  * Performed variable transformations as appropriate for the modeling technique chosen (e.g. MoM to account for nonstationarity in case of a linear regression)
  * Performed variable selection using exhuastive search
  * Performed assumption testing of the final model
  * Performed in-sample and out-of-sample backtesting, and calculated fit metrics
  * Performed sensitivity/scenario analysis with +/- 2 standard deviation shocks
  * Performed coefficient stability testing
  * Performed k-fold cross-validation
  

##1. Trends in Remittance Prices Across Time, Regions, Countries, Currencies and Corridors

In order to get a "feel" for the data and perform conditional sub-setting of different variables *sqldf* library was utilized.

```{r include=FALSE, cache=FALSE, warning=FALSE}
#Loading necessary libraries

library(sqldf)
library(ggplot2)
library(leaps)
library(tseries)
library(fUnitRoots)
library(car)
library(stats)
library(knitr)
library("het.test")
library(DAAG)
library(tcltk)
#library(plyr)
```

```{r include=FALSE, cache=FALSE, warning=FALSE}
#Let's import all the data and some basic cleaning/preparation for further analysis
DataSet <- read.csv("C:/FXComparedProject/DataSet.csv")
attach(DataSet)
Inputs <- read.csv("C:/FXComparedProject/Inputs.csv")
attach(Inputs)
Modeling_Data_Interpolated <- read.csv("C:/FXComparedProject/Modeling_Data_Interpolated.csv")
attach(Modeling_Data_Interpolated)
In.Sample.raw <- read.csv("C:/FXComparedProject/In.Sample.raw.csv")
Out.of.Sample <- read.csv("C:/FXComparedProject/Out-of-Sample.csv")

#Rename the variables in order to use sqldf library:
sending_location <- sending.location
speed_actual <- speed.actual
cc1_lcu_amount <- cc1.lcu.amount
cc1_denomination_amount <- cc1.denomination.amount
cc1_lcu_code <- cc1.lcu.code
cc1_lcu_fee <- cc1.lcu.fee
cc1_lcu_fx_rate <- cc1.lcu.fx.rate
cc1_fx_margin <- cc1.fx.margin
cc1_total_cost <- cc1.total.cost..
inter_lcu_bank_fx <- inter.lcu.bank.fx

#Put everything back into one data frame:
World_Bank_Data <- data.frame(id, period, source_code, source_name,
                              source_region, source_income, source_lending,
                              source_G8G20, destination_code, destination_name,
                              destination_region, destination_income, destination_lending,
                              destination_G8G20, firm, firm_type, product,
                              sending_location, speed_actual, cc1_lcu_amount, 
                              cc1_denomination_amount, cc1_lcu_code, cc1_lcu_fee,
                              cc1_lcu_fx_rate, cc1_fx_margin, cc1_total_cost,
                              inter_lcu_bank_fx, transparent, note1, note2, date)

```


How does the volume (transaction counts) of transactions look like across different source countries?  What is their level of income?

```{r echo=FALSE, warning=FALSE, fig.width=12, fig.height=10}

qplot(source_code, data=World_Bank_Data, fill=source_income, main = "Histogram of Source Countries with Color Coding for Source Income Type", xlab = "Country Codes", ylab = "Counts")
```

How does the volume of transactions look like across all sources by income type?

```{r echo=FALSE, warning=FALSE}

qplot(source_income, data=World_Bank_Data, xlab = "Income Type", ylab = "Log of Counts", log = "y", main = "Histogram of Income Types of Source Countries")
```

How does the volume (transaction counts) of transactions look like across different destination countries? What is their level of income?

```{r echo=FALSE, warning=FALSE, fig.width=15, fig.height=7}

qplot(destination_code, data=World_Bank_Data, fill = destination_income, xlab = "Income Type", ylab = "Log of Counts", log = "y", main = "Histogram of Income Types of Destination Countries") + theme(axis.text.x = element_text(angle=90, vjust=1))

```

How does the volume of transactions look like across all destinations by income type?

```{r echo=FALSE, warning=FALSE}
qplot(destination_income, data=World_Bank_Data, xlab = "Income Type", ylab = "Log of Counts", log = "y", main = "Histogram of Income Types of Destination Countries")
```

How do the average remittance costs vary across time?  Are they increasing/decreasing (i.e. what is the trend?)

To answer this question, let's produce a scatter plot of the date including a trend line (generated by locally weighted scatterplot smoothing) with 95% confidence bands:
```{r echo=FALSE, warning=FALSE, fig.width=10, fig.height=7}

ggplot(data=Inputs, aes(x=Date, y=Total_Cost_Perc, group=1)) + 
  geom_point() + geom_smooth() +
  theme(axis.text.x = element_text(angle=90, vjust=1)) +
  ylab("Average Remittance Cost %") +
  labs(title="Time Series of Average Remittance Costs")
```

LOESS smoother is very flexible, and it's a bit hard to judge the overal trend of remittance costs, since the confidence bands are too wide in this case.  There is also a lot of noise on the boundaries due to high variance in the data.  Let's try a simple linear regression line:

```{r echo=FALSE, warning=FALSE, fig.width=10, fig.height=7}
ggplot(data=Inputs, aes(x=Date, y=Total_Cost_Perc, group=1)) + 
  geom_point() + geom_smooth(method="lm")+
  theme(axis.text.x = element_text(angle=90, vjust=1)) +
  ylab("Average Remittance Cost %") +
  labs(title="Time Series of Average Remittance Costs")
```

Linear trend line worked better in this case.  One can note that the average remittance costs tend to decrease over time.  Similarly, let's take a look at the average remittance costs across different source regions:

```{r echo=FALSE, warning=FALSE, fig.width=10, fig.height=5}
#Aggregate average remittance cost by source region
df <- data.frame(sqldf('select AVG(cc1_total_cost), source_region from World_Bank_Data group by Source_region'))

ggplot(data = df, aes(y = AVG.cc1_total_cost., x=source_region)) + geom_bar(stat="identity") + labs(title="Average Remittance Costs by Region for Source Regions") + ylab("Average Remittance Cost") + xlab("Source Region")
```

Now, let's take a look at the average remittance cost across different destination regions:

```{r warning=FALSE, echo=FALSE, fig.width=12, fig.height=6}
#Aggregate average remittance costs by destination region
df1 <- data.frame(sqldf('select AVG(cc1_total_cost), destination_region from World_Bank_Data group by destination_region'))

ggplot(data = df1, aes(y = AVG.cc1_total_cost., x=destination_region)) + 
  geom_bar(stat="identity") + 
  labs(title="Average Remittance Costs by Region for Destination Regions") + ylab("Average Remittance Cost") + 
  xlab("Destination Region")
```

Average remittance costs by source countries:

```{r warning=FALSE, echo=FALSE}

#Aggregate average remittance costs by countries
df2 <- data.frame(sqldf('select AVG(cc1_total_cost), source_code from World_Bank_Data group by source_code'))

ggplot(data = df2, aes(y = AVG.cc1_total_cost., x=source_code)) + 
  geom_bar(stat="identity") + 
  labs(title="Average Remittance Costs by Source Country") + ylab("Average Remittance Cost") + 
  xlab("Source Country")+
  theme(axis.text.x = element_text(angle=90, vjust=1))

```

Average remittance costs by destination countries:
```{r warning=FALSE, echo=FALSE, fig.width=15, fig.height=7}

#Aggregate average remittance costs by countries
df3 <- data.frame(sqldf('select AVG(cc1_total_cost), destination_code from World_Bank_Data group by destination_code'))

ggplot(data = df3, aes(y = AVG.cc1_total_cost., x=destination_code)) + 
  geom_bar(stat="identity") + 
  labs(title="Average Remittance Costs by Destination Country") + 
  ylab("Average Remittance Cost") + 
  xlab("Source Country")+ 
  xlab("Source Country")+
  theme(axis.text.x = element_text(angle=90, vjust=1))

```

Average remittance costs by currency:
```{r warning=FALSE, echo=FALSE}

df4 <- data.frame(sqldf('select AVG(cc1_total_cost), cc1_lcu_code from World_Bank_Data group by cc1_lcu_code'))

ggplot(data = df4, aes(y = AVG.cc1_total_cost., x=cc1_lcu_code)) + 
  geom_bar(stat="identity") + 
  labs(title="Average Remittance Costs by Currency") + 
  ylab("Average Remittance Cost") + 
  xlab("Currency") + 
  theme(axis.text.x = element_text(angle=90, vjust=1))

```

Average remittance costs by corridor:
```{r warning=FALSE, echo=FALSE, fig.width=15, fig.height=7}

df5 <- data.frame(sqldf('select AVG(cc1_total_cost), source_code, destination_code from World_Bank_Data group by source_code, destination_code'))

ggplot(df5, aes(destination_code, source_code)) +
  geom_point(aes(size = AVG.cc1_total_cost., color=source_code))+
  theme(axis.text.x = element_text(angle=90, vjust=1)) +
  labs(title="Average Remittance Cost by Corridor") +
  xlab("Destination Country") +
  ylab("Source Country")
```

##2. Trends, patterns by sending channel (e.g. bank, money transfer operator).

```{r echo=FALSE, warning=FALSE}

df9 <- data.frame(sqldf('select AVG(cc1_total_cost), firm_type from World_Bank_Data group by firm_type'))

df10 <- data.frame(sqldf('select count(cc1_total_cost), firm_type from World_Bank_Data group by firm_type'))

df11 <- data.frame(sqldf('select MAX(cc1_total_cost), firm_type from World_Bank_Data group by firm_type'))

df12 <- data.frame(sqldf('select MIN(cc1_total_cost), firm_type from World_Bank_Data group by firm_type'))

ggplot(data = df9, aes(y = AVG.cc1_total_cost., x=firm_type)) +
  geom_bar(stat="identity") + 
  labs(title="Average Remittance Costs by Sending Channel") +
  ylab("Average Remittance Cost %") +
  xlab("") +
  theme(axis.text.x = element_text(angle=90, vjust=1))

ggplot(data = df10, aes(y = count.cc1_total_cost., x=firm_type)) +
  geom_bar(stat="identity") +
  scale_y_log10() +
  labs(title="Volume of Remittance Transactions by Sending Channel") +
  ylab("Log Base 10 Volume") + 
  xlab("") +
  theme(axis.text.x = element_text(angle=90, vjust=1))

ggplot(data = df11, aes(y = MAX.cc1_total_cost., x=firm_type)) +
  geom_bar(stat="identity") + 
  labs(title="Maximum Remittance Costs by Sending Channel") +
  ylab("Maximum Remittance Cost %") +
  xlab("") +
  theme(axis.text.x = element_text(angle=90, vjust=1))
  
ggplot(data = df12, aes(y = MIN.cc1_total_cost., x=firm_type)) +
  geom_bar(stat="identity") + 
  labs(title="Minimum Remittance Costs by Sending Channel") +
  ylab("Minimum Remittance Cost %") + 
  xlab("") +
  theme(axis.text.x = element_text(angle=90, vjust=1))

```


##3. Strongest Predictors of Remittance Prices (Limited to the Variables Included in the Dataset)

In this section, I will not only show what are the strongest predictors (drivers that explain most variance in the remittance costs), but I will also develop a timeseries model to predict remittance costs in the future.  The modeling frameworks explored include linear regression, lasso, ridge, and splines.  However, for the purposes of saving space and time, I will only show the final model - linear regression (workpapers for other models are available upon request).  Transformations of the target and the driver variables considered are MoM, MoM% and log MoM.  The variable selection process was done using exhaustive search (sorted by adjusted-$R^2$), and then economic/business rationale was applied to pick out the best model.

First, let's show which predictors are the "strongest" using Pearson Product-Moment Correlation test:

```{r echo=FALSE}

#we use Pearson correlation test to find the strongest predictors

cor.test(Modeling_Data_Interpolated$Avg_cost, Modeling_Data_Interpolated$Avg_Bank_fx)
cor.test(Modeling_Data_Interpolated$Avg_cost, Modeling_Data_Interpolated$Avg_Bank_fx_margin)
cor.test(Modeling_Data_Interpolated$Avg_cost, Modeling_Data_Interpolated$Avg_fx_lcu_rate)
cor.test(Modeling_Data_Interpolated$Avg_cost, Modeling_Data_Interpolated$Avg__lcu_fee)


```

Thus, the strongest predictor of remittance costs is FX margin (highest correlation coefficient and p < 0.05 threshold).  Next, we will build a simple regression model (linear regression with a single predictor) with these timeseries.  One of the most important assumptions of linear regression is stationarity of the target variables and the drivers.  We will utilize Augumented Dickey Fuller test for that:

```{r echo=FALSE}

adf.test(Modeling_Data_Interpolated$Avg_cost)

adf.test(Modeling_Data_Interpolated$Avg_Bank_fx_margin)

```

All p-values are less than 0.05 significance threshold.  Thus, we reject the null hypothesis of nonstationarity, i.e. both variables are stationary.  Next, we need to partition our timeseries into in-sample and out-of-sample datasets, and run the regression:


```{r warning=FALSE, echo=FALSE, fig.width=30, fig.height=10}

y <- In.Sample.raw$Average.of.cc2.total.cost..
x<- In.Sample.raw$Average.of.cc2.fx.margin

model <- lm(y ~ x)
summary(model)
```

From the the *lm()* output, we note that FX Margin variable is significant (i.e. p-value is less than 0.05), and $R^2$ and adjusted $R^2$ are very high (91.56% and 91.35%, respectfully).  The coefficient of FX margin is positive, which makes sense since if FX margin increases - the remittance costs are expected to increase as well (and vice versa). 

Next, we need to perform assumption testing to make sure that this is a sensible model:

```{r warning=FALSE}

############################
##    Linearity Testing   ##  
############################

# Evaluate Nonlinearity
# component + residual plot 
crPlots(model, main="Component + Residual Plot")

#Scatter plot of Remittance costs vs. Fx margin with a fitted trend line
qplot(x, y, geom=c("point"), main="Scatter Plot of Remittance costs vs. Fx Margin with a Fitted Trend Line") +
  geom_smooth(method="lm") +
  xlab("FX Margin") +
  ylab("Remittance Costs %")



############################
##       Collinearity     ##  
############################

#There is one variable in the model, thus collinearity testing is not applicable here.

############################
##    Homoscedasticity    ##  
############################

# Evaluate homoscedasticity  Breusch-Pagan test
# non-constant error variance test  Breusch-Pagan test
bptest(model)
# plot studentized residuals vs. fitted values 
spreadLevelPlot(model)


##############################
## Residual Autocorrelation ##  
##############################

dwtest(model)

bgtest(model)

##############################
##    Residual Normality    ##  
##############################

# Normality of Residuals
# qq plot for studentized resid
qqnorm(model$residuals, main="QQ Plot")
qqline(model$residuals)

# distribution of studentized residuals
sresid <- studres(model) 
hist(sresid, freq=FALSE, 
     main="Distribution of Studentized Residuals")
xmodel<-seq(min(sresid),max(sresid),length=40) 
ymodel<-dnorm(xmodel) 
lines(xmodel, ymodel)

shapiro.test(model$residuals)
jarque.bera.test(model$residuals)



```

Our model satisfied all of the assumption tests. Next, we perform in-sample and out-of-sample backtesting of the model, and calculate MPE, MAPE and RMSE fit metrics. 

In-Sample Backtesting:

```{r echo=FALSE, fig.width=10, fig.height=5}

df7 <-data.frame(In.Sample.raw$Date,In.Sample.raw$Average.of.cc2.total.cost.., predict(model, interval = "confidence"))

ggplot(df7, aes(In.Sample.raw.Date, group = 1)) +
  geom_point(aes(y=In.Sample.raw.Average.of.cc2.total.cost.., colour = "Average Remittance Cost")) +
  geom_line(aes(y=fit, colour = "Fitted Average Remittance Cost")) +
  geom_line(aes(y=lwr, colour = "Lower 95% Confidence Bound")) +
  geom_line(aes(y=upr, colour = "Upper 95% Confidnce Bound")) +
  labs(x = "Date", y = "Average Remittance Cost %", title = "In-Sample Backtesting") +
  theme(axis.text.x = element_text(angle=90, vjust=1))

```

Out-of-sample backtesting:

```{r echo=FALSE}

new <- data.frame(Out.of.Sample$Average.of.cc2.fx.margin)
names(new)[1] <- "x"

df8 <- data.frame(Out.of.Sample$Date, Out.of.Sample$Average.of.cc2.total.cost.., predict(model, newdata = new, interval = "confidence"))

ggplot(df8, aes(Out.of.Sample.Date, group = 1)) +
  geom_point(aes(y=Out.of.Sample.Average.of.cc2.total.cost.., colour = "Average Remittance Cost")) +
  geom_line(aes(y=fit, colour = "Fitted Average Remittance Cost")) +
  geom_line(aes(y=lwr, colour = "Lower 95% Confidence Bound")) +
  geom_line(aes(y=upr, colour = "Upper 95% Confidnce Bound")) +
  labs(x = "Date", y = "Average Remittance Cost %", title = "Out-of-Sample Backtesting") +
  theme(plot.title = element_text(size=22), plot.title = element_text(size=22), axis.text.x = element_text(angle=90, vjust=1))

```

Let's calculate the fit metrics and parse them into a table for comparison:

```{r echo=FALSE}
#In-Sample fit metrics
MPE.In.Sample <- mean((df7$In.Sample.raw.Average.of.cc2.total.cost.. - df7$fit)/df7$In.Sample.raw.Average.of.cc2.total.cost..)*100
MAPE.In.Sample <- mean(abs((df7$In.Sample.raw.Average.of.cc2.total.cost.. - df7$fit)/df7$In.Sample.raw.Average.of.cc2.total.cost..))*100
RMSE.In.Sample <- sqrt(mean((df7$In.Sample.raw.Average.of.cc2.total.cost.. - df7$fit)^2))
# R_sq.In.Sample <- 0.9156 * 100

#Out-of-Sample fit metrics
MPE.Out.of.Sample <- mean((df8$Out.of.Sample.Average.of.cc2.total.cost.. - df8$fit)/df8$Out.of.Sample.Average.of.cc2.total.cost..)*100
MAPE.Out.of.Sample <- mean(abs((df8$Out.of.Sample.Average.of.cc2.total.cost.. - df8$fit)/df8$Out.of.Sample.Average.of.cc2.total.cost..))*100
RMSE.Out.of.Sample <- sqrt(mean((df8$Out.of.Sample.Average.of.cc2.total.cost.. - df8$fit)^2))
# R_sq.Out.of.Sample <- (1 -(sum((df8$Out.of.Sample.Average.of.cc2.total.cost.. - df8$fit)^2)/ sum((df8$Out.of.Sample.Average.of.cc2.total.cost.. - mean(df8$Out.of.Sample.Average.of.cc2.total.cost..))^2)))*100

#Parsing into the table
Fit_Metric <- c("MPE", "MAPE", "RMSE")
In_Sample_Metric <- c(MPE.In.Sample, MAPE.In.Sample, RMSE.In.Sample)
Out_of_Sample_Metric <- c(MPE.Out.of.Sample, MAPE.Out.of.Sample, RMSE.Out.of.Sample)

table_data <- data.frame(Fit_Metric, In_Sample_Metric, Out_of_Sample_Metric)

kable(table_data, format = "markdown")

```

Next, we'll explore how sensitive this model to +/- 2std scenario shocks in FX margin:

```{r echo=FALSE, fig.width=10, fig.height=5}

stand.dev <- stdev(Modeling_Data_Interpolated$Avg_Bank_fx_margin)

#prepare the data
fx_margin_neg_shock <- Out.of.Sample$Average.of.cc2.fx.margin - 2*stand.dev
fx_margin_pos_shock <- Out.of.Sample$Average.of.cc2.fx.margin + 2*stand.dev
base <- Out.of.Sample$Average.of.cc2.fx.margin

#create a temporary variable
x1 <- as.data.frame(fx_margin_neg_shock)
names(x1)[1] <- "x"

#get predicted values
fx_margin_neg_shock_pred <- predict(model, newdata = x1)

#create a temporary variable
x1 <- as.data.frame(fx_margin_pos_shock)
names(x1)[1] <- "x"

#get predicted values
fx_margin_pos_shock_pred <- predict(model, newdata = x1)

#create a temporary variable
x1 <- as.data.frame(base)
names(x1)[1] <- "x"

#get predicted values
base_pred <- predict(model, newdata = x1)

#aggregate the data into a data frame for ggplot

scenarios <- data.frame(Out.of.Sample$Date, base_pred,fx_margin_pos_shock_pred, fx_margin_neg_shock_pred)

#plot the predicted values under scenarios

ggplot(scenarios, aes(x=Out.of.Sample.Date, group = 1)) +
  geom_line(aes(y=base_pred, colour = "Base Projection")) +
  geom_line(aes(y=fx_margin_pos_shock_pred, colour = "+ 2 std shock")) +
  geom_line(aes(y=fx_margin_neg_shock_pred, colour = "- 2 std shock")) +
  labs(x = "Date", y = "Average Remittance Cost %", title = "Scenario Analysis with Shocked FX Margin")

```

Stability Testing:

```{r echo=FALSE, fig.width=10, fig.height=5}

#Get model coefficients for the stability test:
coefficients.stab <- data.frame()
for(i in 1:30){
  j = 43 - i
  model.stab <- lm(y[1:j] ~ x[1:j])
  coefficients.stab <- rbind(coefficients.stab, model.stab$coefficients[2])
}

names(coefficients.stab)[1] <- "x"

#aggregate into a dataframe and plot
model.stab.data <- data.frame(In.Sample.raw$Date[13:42], coefficients.stab)
names(model.stab.data)[1] <- "Date"

ggplot(model.stab.data, aes(x=Date, group = 1)) +
  geom_line(aes(y=x)) +
  theme(axis.text.x = element_text(angle=90, vjust=1)) +
  labs(title="Stability Testing for the Regression Coefficient")

```

As we can see from the plot above, the coefficient never changes it's sign, i.e. the relationship between the target variable (remittance costs) and the driver (FX margin) is stable. Next, we estimate the test error using the k-fold cross validation with $k = 10$.

```{r echo=FALSE}
cv.data <- data.frame(y,x)

cv.lm(data=cv.data,model, m=10)

```

Lastly, since our model passed all the testing, we are going to re-estimate our model on the whole data set (in-sample + out-of-sample) to get our final model:

```{r echo=FALSE}

avg_rem_cost_perc <- Modeling_Data_Interpolated$Avg_cost
avg_fx_margin <- Modeling_Data_Interpolated$Avg_Bank_fx_margin

final.model <- lm(avg_rem_cost_perc ~ avg_fx_margin)

summary(final.model)

```


Our final model takes the form: Average Remittance Cost % = 2.26 + 1.10*Average FX Margin